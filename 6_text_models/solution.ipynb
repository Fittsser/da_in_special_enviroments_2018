{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:25:53.355299Z",
     "start_time": "2018-07-31T07:25:53.342601Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:26:05.347844Z",
     "start_time": "2018-07-31T07:26:04.480103Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.tsv\", sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:26:05.375221Z",
     "start_time": "2018-07-31T07:26:05.350908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>с конец 1811 го год начаться усиленный вооруже...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 июнь сила западный европа переслать граница...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>миллион человек совершать друг против друг так...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>что произвести это необычайный событие</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>какой быть причина он</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                true\n",
       "0  с конец 1811 го год начаться усиленный вооруже...\n",
       "1  12 июнь сила западный европа переслать граница...\n",
       "2  миллион человек совершать друг против друг так...\n",
       "3             что произвести это необычайный событие\n",
       "4                              какой быть причина он"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:26:05.927436Z",
     "start_time": "2018-07-31T07:26:05.905635Z"
    }
   },
   "outputs": [],
   "source": [
    "BOS = \"BOS\"\n",
    "EOS = \"EOS\"\n",
    "UNK = \"UNK\"\n",
    "\n",
    "def prepare_sentences(sentences, word_threshold=2, stage_train=True):\n",
    "    print(type(sentences[0]), re.split(\"\\W+\", sentences[0]))\n",
    "    \n",
    "    # оставляем только alphanumeric\n",
    "    clean_sentences = [re.split(\"\\W+\", str(s)) for s in sentences]\n",
    "    \n",
    "    # заменяем числа на NUM\n",
    "    clean_sentences = [[w.replace(\"\\d+\", \"NUM\") for w in s if w] for s in clean_sentences]\n",
    "    \n",
    "    # вводим тег UNKNOWN: UNK\n",
    "    if stage_train:\n",
    "        counter = Counter()\n",
    "\n",
    "        for s in clean_sentences:\n",
    "            for w in s:\n",
    "                counter[w] += 1\n",
    "    \n",
    "        print(\"Filtered out word types :\", len([w for w in counter if counter[w] <= word_threshold]))\n",
    "        print(\"Filtered out words count:\", sum([counter[w] for w in counter if counter[w] <= word_threshold]))\n",
    "    \n",
    "        # выкидываем редкие, и заменяем их на специальный тег\n",
    "        clean_sentences = [[w if counter[w] > word_threshold else UNK for w in s] for s in clean_sentences]            \n",
    "    \n",
    "    word2index = { BOS: 0, EOS: 1, UNK: 2}\n",
    "    index2word = { 0: BOS, 1: EOS, 2: UNK}\n",
    "    \n",
    "    counter = max(word2index.values()) + 1\n",
    "\n",
    "    for s in clean_sentences:\n",
    "        for w in s:\n",
    "            if not w in word2index:\n",
    "                word2index[w] = counter\n",
    "                index2word[counter] = w\n",
    "                counter += 1\n",
    "                \n",
    "    return word2index, index2word, clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:26:08.982733Z",
     "start_time": "2018-07-31T07:26:07.922426Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ['с', 'конец', '1811', 'го', 'год', 'начаться', 'усиленный', 'вооружение', 'и', 'сосредоточение', 'сила', 'западный', 'европа', 'и', 'в', '1812', 'год', 'сила', 'этот', 'миллион', 'человек', 'считать', 'тот', 'который', 'перевозить', 'и', 'кормить', 'армия', 'двинуться', 'с', 'запад', 'на', 'восток', 'к', 'граница', 'россия', 'к', 'который', 'точно', 'так', 'же', 'с', '1811', 'го', 'год', 'стягиваться', 'сила', 'россия']\n",
      "Filtered out word types : 8565\n",
      "Filtered out words count: 10787\n"
     ]
    }
   ],
   "source": [
    "word2index, index2word, clean_sentences = prepare_sentences(df[\"true\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:26:08.994896Z",
     "start_time": "2018-07-31T07:26:08.985890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['с',\n",
       "  'конец',\n",
       "  '1811',\n",
       "  'го',\n",
       "  'год',\n",
       "  'начаться',\n",
       "  'усиленный',\n",
       "  'вооружение',\n",
       "  'и',\n",
       "  'UNK',\n",
       "  'сила',\n",
       "  'западный',\n",
       "  'европа',\n",
       "  'и',\n",
       "  'в',\n",
       "  '1812',\n",
       "  'год',\n",
       "  'сила',\n",
       "  'этот',\n",
       "  'миллион',\n",
       "  'человек',\n",
       "  'считать',\n",
       "  'тот',\n",
       "  'который',\n",
       "  'UNK',\n",
       "  'и',\n",
       "  'кормить',\n",
       "  'армия',\n",
       "  'двинуться',\n",
       "  'с',\n",
       "  'запад',\n",
       "  'на',\n",
       "  'восток',\n",
       "  'к',\n",
       "  'граница',\n",
       "  'россия',\n",
       "  'к',\n",
       "  'который',\n",
       "  'точно',\n",
       "  'так',\n",
       "  'же',\n",
       "  'с',\n",
       "  '1811',\n",
       "  'го',\n",
       "  'год',\n",
       "  'UNK',\n",
       "  'сила',\n",
       "  'россия'],\n",
       " ['12',\n",
       "  'июнь',\n",
       "  'сила',\n",
       "  'западный',\n",
       "  'европа',\n",
       "  'переслать',\n",
       "  'граница',\n",
       "  'россия',\n",
       "  'и',\n",
       "  'начаться',\n",
       "  'война',\n",
       "  'то',\n",
       "  'есть',\n",
       "  'совершиться',\n",
       "  'противный',\n",
       "  'человеческий',\n",
       "  'разум',\n",
       "  'и',\n",
       "  'весь',\n",
       "  'человеческий',\n",
       "  'природа',\n",
       "  'событие'],\n",
       " ['миллион',\n",
       "  'человек',\n",
       "  'совершать',\n",
       "  'друг',\n",
       "  'против',\n",
       "  'друг',\n",
       "  'такой',\n",
       "  'бесчисленный',\n",
       "  'количество',\n",
       "  'злодеяние',\n",
       "  'обман',\n",
       "  'измена',\n",
       "  'воровство',\n",
       "  'UNK',\n",
       "  'и',\n",
       "  'UNK',\n",
       "  'фальшивый',\n",
       "  'ассигнация',\n",
       "  'грабёж',\n",
       "  'поджог',\n",
       "  'и',\n",
       "  'убийство',\n",
       "  'который',\n",
       "  'в',\n",
       "  'целое',\n",
       "  'век',\n",
       "  'не',\n",
       "  'собрать',\n",
       "  'UNK',\n",
       "  'весь',\n",
       "  'UNK',\n",
       "  'мир',\n",
       "  'и',\n",
       "  'на',\n",
       "  'который',\n",
       "  'в',\n",
       "  'этот',\n",
       "  'период',\n",
       "  'время',\n",
       "  'человек',\n",
       "  'совершать',\n",
       "  'они',\n",
       "  'не',\n",
       "  'смотреть',\n",
       "  'как',\n",
       "  'на',\n",
       "  'преступление'],\n",
       " ['что', 'произвести', 'это', 'необычайный', 'событие'],\n",
       " ['какой', 'быть', 'причина', 'он'],\n",
       " ['историк',\n",
       "  'с',\n",
       "  'наивный',\n",
       "  'уверенность',\n",
       "  'говорят',\n",
       "  'что',\n",
       "  'причина',\n",
       "  'это',\n",
       "  'событие',\n",
       "  'быть',\n",
       "  'обида',\n",
       "  'нанести',\n",
       "  'герцог',\n",
       "  'ольденбургский',\n",
       "  'несоблюдение',\n",
       "  'континентальный',\n",
       "  'система',\n",
       "  'UNK',\n",
       "  'наполеон',\n",
       "  'твёрдость',\n",
       "  'александр',\n",
       "  'ошибка',\n",
       "  'дипломат',\n",
       "  'и',\n",
       "  'том'],\n",
       " ['плата'],\n",
       " ['следовательно',\n",
       "  'стоить',\n",
       "  'только',\n",
       "  'меттерниха',\n",
       "  'румянцев',\n",
       "  'или',\n",
       "  'талейрана',\n",
       "  'между',\n",
       "  'выход',\n",
       "  'и',\n",
       "  'UNK',\n",
       "  'хорошенько',\n",
       "  'постараться',\n",
       "  'и',\n",
       "  'написать',\n",
       "  'искусный',\n",
       "  'бумажка',\n",
       "  'или',\n",
       "  'наполеон',\n",
       "  'написать',\n",
       "  'к',\n",
       "  'александр',\n",
       "  'monsieur',\n",
       "  'mon',\n",
       "  'fr',\n",
       "  '232',\n",
       "  're',\n",
       "  'je',\n",
       "  'UNK',\n",
       "  '224',\n",
       "  'UNK',\n",
       "  'le',\n",
       "  'UNK',\n",
       "  '233',\n",
       "  'au',\n",
       "  'duc',\n",
       "  'd',\n",
       "  'UNK',\n",
       "  '1',\n",
       "  'государь',\n",
       "  'брат',\n",
       "  'мой',\n",
       "  'я',\n",
       "  'соглашаться',\n",
       "  'возвратить',\n",
       "  'UNK',\n",
       "  'ольденбургский',\n",
       "  'герцог'],\n",
       " ['и', 'война', 'бы', 'не', 'быть'],\n",
       " ['понятно', 'что', 'такой', 'представляться', 'дело', 'современник']]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:26:11.300930Z",
     "start_time": "2018-07-31T07:26:11.243848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences :\t 14996\n",
      "Total number of words     :\t 228126\n",
      "Total number of word types:\t 6409\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of sentences :\\t\", len(clean_sentences))\n",
    "print(\"Total number of words     :\\t\", sum([len(sent) for sent in clean_sentences]))\n",
    "print(\"Total number of word types:\\t\", len(set([w for sent in clean_sentences for w in sent])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:26:12.192797Z",
     "start_time": "2018-07-31T07:26:12.186065Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment(sentence, context_size):\n",
    "    \"\"\"\n",
    "        Добиваем символы начала и конца строки к каждому предложению\n",
    "    \"\"\"\n",
    "    return [BOS] * context_size + sentence + [EOS] * context_size\n",
    "\n",
    "def enumerate_sentences(clean_sentences, context_size, word2index):\n",
    "    \"\"\"\n",
    "        Добиваем символами начала и конца и конвертируем слова в индексы\n",
    "    \"\"\"\n",
    "\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    UNK_id = word2index[UNK]\n",
    "\n",
    "    for sentence in clean_sentences:\n",
    "\n",
    "        aligned_sentence =  augment(sentence, context_size) \n",
    "\n",
    "        for i in range(context_size, len(sentence) - context_size, 1):\n",
    "            \n",
    "            # берём предшествующий контекст\n",
    "            context = aligned_sentence[i - context_size:i]\n",
    "            context = [word2index[c] if c in word2index else UNK_id for c in context]\n",
    "            target = word2index[aligned_sentence[i]] if aligned_sentence[i] in word2index else UNK_id\n",
    "            \n",
    "            contexts.append(context)\n",
    "            targets.append(target)\n",
    "    \n",
    "    return contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:26:13.422483Z",
     "start_time": "2018-07-31T07:26:13.418105Z"
    }
   },
   "outputs": [],
   "source": [
    "def chunks(l0, l1, n):\n",
    "    \n",
    "    assert len(l0) == len(l1)\n",
    "    coll0, coll1 = [], []\n",
    "    \n",
    "    for i in range(0, len(l0), n):\n",
    "        coll0.append(l0[i:i + n])\n",
    "        coll1.append(l1[i:i + n])\n",
    "        \n",
    "    return coll0, coll1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:31:28.207990Z",
     "start_time": "2018-07-31T07:31:27.660885Z"
    }
   },
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 3\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "# строим контексты и цели\n",
    "contexts, targets = enumerate_sentences(clean_sentences, CONTEXT_SIZE, word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:31:31.969617Z",
     "start_time": "2018-07-31T07:31:31.961162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0],\n",
       " [0, 0, 3],\n",
       " [0, 3, 4],\n",
       " [3, 4, 5],\n",
       " [4, 5, 6],\n",
       " [5, 6, 7],\n",
       " [6, 7, 8],\n",
       " [7, 8, 9],\n",
       " [8, 9, 10],\n",
       " [9, 10, 11]]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:31:33.924453Z",
     "start_time": "2018-07-31T07:31:32.229409Z"
    }
   },
   "outputs": [],
   "source": [
    "batches = list(zip(contexts, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:31:35.231342Z",
     "start_time": "2018-07-31T07:31:35.225745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0, 0, 0], 3),\n",
       " ([0, 0, 3], 4),\n",
       " ([0, 3, 4], 5),\n",
       " ([3, 4, 5], 6),\n",
       " ([4, 5, 6], 7),\n",
       " ([5, 6, 7], 8),\n",
       " ([6, 7, 8], 9),\n",
       " ([7, 8, 9], 10),\n",
       " ([8, 9, 10], 11),\n",
       " ([9, 10, 11], 2)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:33:07.700044Z",
     "start_time": "2018-07-31T07:33:07.690362Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook\n",
    "from functools import lru_cache\n",
    "\n",
    "class NGramFreqsLanguageModeler(object):\n",
    "    \n",
    "    def __init__(self, vocab_size, context_size):\n",
    "        # не обязательная часть, насколько я понимаю\n",
    "        # super(NGramFreqsLanguageModeler, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.context_size = context_size\n",
    "        # вероятности всех слов после этого контекста\n",
    "        self.ngram_dict = defaultdict(lambda: defaultdict(int))\n",
    "        # То же самое, что ngram_dict, только длина контекста = 2. Зачем?\n",
    "        self.n_1_gram_dict = defaultdict(lambda: defaultdict(int))\n",
    "        # количество раз сколько встречается каждый контекст\n",
    "        self.contexts_counts = defaultdict(int)\n",
    "        # коэффициент лапласовского сглаживания\n",
    "        self.eps = .1\n",
    "    \n",
    "    def fit(self, contexts, targets):\n",
    "        \n",
    "        self.contexts_counts = defaultdict(int)\n",
    "        \n",
    "        for c, t in zip(contexts, targets):\n",
    "            c = tuple(c)\n",
    "            self.ngram_dict[c][t] += 1\n",
    "            self.contexts_counts[c] += 1\n",
    "            \n",
    "            # намёк!\n",
    "#             self.n_1_gram_dict[c[1:]][t] += 1\n",
    "\n",
    "            \n",
    "        print(\"Total n-1 grams\", len(self.ngram_dict), list(self.ngram_dict)[:10])\n",
    "        \n",
    "        # нормализуем частоты\n",
    "        for c in tqdm_notebook(self.ngram_dict.keys()):\n",
    "            for t in self.ngram_dict[c]:\n",
    "                # нормируем слово в контексте на количество таких контекстов и общее количество слов\n",
    "                self.ngram_dict[c][t] = (self.ngram_dict[c][t] +  self.eps) / \\\n",
    "                                            (self.contexts_counts[c] + self.vocab_size * self.eps)\n",
    "        \n",
    "    @lru_cache(1000000)\n",
    "    def prob_dist(self, input_context):\n",
    "        \"\"\"\n",
    "            Takes ngram as a tuple\n",
    "        \"\"\"\n",
    "        \n",
    "        probs = np.zeros(self.vocab_size) + \\\n",
    "                    self.eps / (self.vocab_size * self.eps + self.contexts_counts[input_context])\n",
    "        \n",
    "        counts = self.ngram_dict[input_context]\n",
    "        \n",
    "        # если есть хоть какие-то счётчики\n",
    "        if counts:\n",
    "            # проставим осмысленные частоты\n",
    "            for target, freq in counts.items():\n",
    "                probs[target] = freq\n",
    "                \n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:33:08.785880Z",
     "start_time": "2018-07-31T07:33:08.405329Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total n-1 grams 112596 [(0, 0, 0), (0, 0, 3), (0, 3, 4), (3, 4, 5), (4, 5, 6), (5, 6, 7), (6, 7, 8), (7, 8, 9), (8, 9, 10), (9, 10, 11)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448e4eec5ca14615bafb9ced4b129f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112596), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "simple_model = NGramFreqsLanguageModeler(context_size=CONTEXT_SIZE, vocab_size=len(word2index))\n",
    "simple_model.fit(contexts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T05:56:42.047408Z",
     "start_time": "2018-07-31T05:56:42.041935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ['B']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EOS', 'EOS', 'EOS']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"BOS\"\n",
    "prepared_text = augment(prepare_sentences(test, stage_train=False)[2][0], CONTEXT_SIZE)[-CONTEXT_SIZE:]\n",
    "prepared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:33:11.679499Z",
     "start_time": "2018-07-31T07:33:11.652643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерация: EOS feu\n",
      "Генерация: EOS feu привыкнуть\n",
      "Генерация: EOS feu привыкнуть владыка\n",
      "Генерация: EOS feu привыкнуть владыка вникать\n",
      "Генерация: EOS feu привыкнуть владыка вникать посердиться\n",
      "Генерация: EOS feu привыкнуть владыка вникать посердиться решение\n",
      "Генерация: EOS feu привыкнуть владыка вникать посердиться решение жёсткий\n",
      "Генерация: EOS feu привыкнуть владыка вникать посердиться решение жёсткий верхом\n",
      "Генерация: EOS feu привыкнуть владыка вникать посердиться решение жёсткий верхом открываться\n",
      "Генерация: EOS feu привыкнуть владыка вникать посердиться решение жёсткий верхом открываться христос\n"
     ]
    }
   ],
   "source": [
    "for i in range(CONTEXT_SIZE, 10 + CONTEXT_SIZE):\n",
    "    \n",
    "    idx = [word2index[w] for w in prepared_text[:i]]    \n",
    "    \n",
    "    predict = simple_model.prob_dist(tuple(idx[-CONTEXT_SIZE:])) \n",
    "    \n",
    "#     predict = predict - predict.min()  \n",
    "#     predict /= sum(predict)\n",
    "    \n",
    "    selected_word = np.random.choice(a=range(len(word2index)), p=predict)    \n",
    "    prepared_text.append(index2word[selected_word])\n",
    "    \n",
    "    print(\"Генерация:\", \" \".join(prepared_text[CONTEXT_SIZE - 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T21:53:06.469888Z",
     "start_time": "2018-07-30T21:53:06.373256Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/task.tsv\", sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1666, 2)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T21:53:13.078420Z",
     "start_time": "2018-07-30T21:53:13.064879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>что есть власть</td>\n",
       "      <td>что власть есть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>власть есть совокупность воля перенести на оди...</td>\n",
       "      <td>лицо воля один перенести есть власть совокупно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>какой переноситься при на воля условие лицо ма...</td>\n",
       "      <td>при какой условие переноситься воля масса на о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>при условие выражение лицо воля весь человек</td>\n",
       "      <td>лицо воля выражение человек весь условие при</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>власть то есть есть власть</td>\n",
       "      <td>то есть власть есть власть</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0                                    что есть власть   \n",
       "1  власть есть совокупность воля перенести на оди...   \n",
       "2  какой переноситься при на воля условие лицо ма...   \n",
       "3       при условие выражение лицо воля весь человек   \n",
       "4                         власть то есть есть власть   \n",
       "\n",
       "                                               text2  \n",
       "0                                    что власть есть  \n",
       "1  лицо воля один перенести есть власть совокупно...  \n",
       "2  при какой условие переноситься воля масса на о...  \n",
       "3       лицо воля выражение человек весь условие при  \n",
       "4                         то есть власть есть власть  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T22:16:58.973136Z",
     "start_time": "2018-07-30T22:16:58.969081Z"
    }
   },
   "outputs": [],
   "source": [
    "def wseq2indexes(wseq):\n",
    "    return tuple([word2index[w] if (w in word2index) else word2index[\"UNK\"] for w in wseq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ['что', 'власть', 'есть']\n",
      "Filtered out word types : 2958\n",
      "Filtered out words count: 3667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1666"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prepare_sentences(df_test[text_n].tolist())[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:33:27.761028Z",
     "start_time": "2018-07-31T07:33:26.491272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> ['что', 'есть', 'власть']\n",
      "Filtered out word types : 2958\n",
      "Filtered out words count: 3667\n",
      "<class 'str'> ['что', 'власть', 'есть']\n",
      "Filtered out word types : 2958\n",
      "Filtered out words count: 3667\n"
     ]
    }
   ],
   "source": [
    "text_probs = {}\n",
    "\n",
    "for text_n in [\"text1\", \"text2\"]:\n",
    "    text_probs[text_n] = defaultdict(int)\n",
    "    \n",
    "    for index, sent in enumerate(prepare_sentences(df_test[text_n].tolist())[2]):\n",
    "#         print(\"\\nTEXT\")\n",
    "        sent = augment(sent, CONTEXT_SIZE)\n",
    "#         print(sent)\n",
    "        for i in range(len(sent) - CONTEXT_SIZE):\n",
    "            context = sent[i: i + CONTEXT_SIZE]\n",
    "            target = sent[i + CONTEXT_SIZE]\n",
    "\n",
    "            context_indexes = wseq2indexes(sent[i: i + CONTEXT_SIZE])\n",
    "\n",
    "            target_index = word2index.get(target, word2index[\"UNK\"])\n",
    "#             print(context_indexes, target_index)\n",
    "\n",
    "            prob = simple_model.ngram_dict[context_indexes][target_index]\n",
    "#             print(prob)\n",
    "            text_probs[text_n][index] += prob\n",
    "\n",
    "#             print(context, target, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1666"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_probs[\"text2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1666"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_probs[\"text2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:33:27.773452Z",
     "start_time": "2018-07-31T07:33:27.764037Z"
    }
   },
   "outputs": [],
   "source": [
    "answers = {}\n",
    "for i in text_probs[\"text1\"]:\n",
    "    answers[i] = 1 if text_probs[\"text1\"][i] >= text_probs[\"text2\"][i] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1666"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_probs[\"text1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:33:28.016693Z",
     "start_time": "2018-07-31T07:33:28.004851Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"data/submission_window3.csv\", \"wt\") as f:\n",
    "    writer = csv.writer(f) \n",
    "    #writer.writerow([\"id\", \"which\"])\n",
    "    for i, answer in answers.items():\n",
    "        writer.writerow([i, answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd.read_csv(\"data/true_labels.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv(\"data/submission_window3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1665, 1), (1665, 2))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6312312312312313"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true.iloc[:, 0].values, y_pred.iloc[:, 1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
